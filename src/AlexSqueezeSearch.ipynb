{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexSqueezeSearch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C3QCAi6I65y"
      },
      "source": [
        "#Utility functions, parameters, and Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y7B7ac5RJlH"
      },
      "source": [
        "#@title General parameters { run: \"auto\", display-mode: \"form\" }\n",
        "from torchvision import transforms\n",
        "import PIL.Image\n",
        "\n",
        "_nb_epochs = 10 #@param {type:\"integer\"}\n",
        "_log_interval = 1 #@param {type:\"integer\"}\n",
        "_dataset = \"CIFAR-10\" #@param [\"ImageNet-16\", \"CIFAR-10\", \"CIFAR-100\", \"CINIC-10\"]\n",
        "\n",
        "# _interpolation_method = \"nearest\" #@param [\"nearest\", \"bilinear\", \"cubic\"]\n",
        "# if \"nearest\" == _interpolation_method:\n",
        "#     _interpolation_method = PIL.Image.NEAREST\n",
        "# elif \"bilinear\" == _interpolation_method:\n",
        "#     _interpolation_method = PIL.Image.BILINEAR\n",
        "# elif \"cubic\" == _interpolation_method:\n",
        "#     _interpolation_method = PIL.Image.CUBIC\n",
        "    \n",
        "_transformations = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(64),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu6PdAGlACRO",
        "cellView": "form"
      },
      "source": [
        "#@title AlexNet parameters\n",
        "\n",
        "_alex_enabled = False #@param {type:\"boolean\"}\n",
        "if _alex_enabled:\n",
        "#     _alex_scheduler=\"Step\" #@param [\"Step\", \"Adaptive\"]\n",
        "#     _alex_step_size=15 #@param {type:\"number\"}\n",
        "#     _alex_gamma = 0.1 #@param {type:\"number\"}\n",
        "    _alex_pretrained = False #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98MeFQMGAbXa",
        "cellView": "form"
      },
      "source": [
        "#@title SqueezeNet parameters\n",
        "\n",
        "# _squeeze_learning_rate = 0.01 #@param {type:\"number\"}\n",
        "# _squeeze_momentum = 0.5 #@param {type:\"number\"}\n",
        "# _squeeze_weight_decay=0.0002 #@param {type:\"number\"}\n",
        "# _squeeze_scheduler=\"Step\" #@param [\"Step\", \"Adaptive\"]\n",
        "# _squeeze_step_size=15 #@param {type:\"number\"}\n",
        "# _squeeze_gamma = 0.1 #@param {type:\"number\"}\n",
        "_squeeze_pretrained = True #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFoc4u5gil6O",
        "cellView": "form"
      },
      "source": [
        "#@title Google Drive {run: \"auto\"}\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "data_folder = '/gdrive/My Drive/COMP551_Assignment3_data/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN1vdP6E7NT7",
        "cellView": "form"
      },
      "source": [
        "#@title Utility functions\n",
        "\n",
        "def log_progress(sequence, every=None, size=None, name='Items'):\n",
        "    from ipywidgets import IntProgress, HTML, VBox\n",
        "    from IPython.display import display\n",
        "    \n",
        "    is_iterator = False\n",
        "    if size is None:\n",
        "        try:\n",
        "            size = len(sequence)\n",
        "        except TypeError:\n",
        "            is_iterator = True\n",
        "    if size is not None:\n",
        "        if every is None:\n",
        "            if size <= 200:\n",
        "                every = 1\n",
        "            else:\n",
        "                every = int(size / 200)     # every 0.5%\n",
        "    else:\n",
        "        assert every is not None, 'sequence is iterator, set every'\n",
        "\n",
        "    if is_iterator:\n",
        "        progress = IntProgress(min=0, max=1, value=1)\n",
        "        progress.bar_style = 'info'\n",
        "    else:\n",
        "        progress = IntProgress(min=0, max=size, value=0)\n",
        "    label = HTML()\n",
        "    box = VBox(children=[label, progress])\n",
        "    display(box)\n",
        "        \n",
        "    index = 0\n",
        "    try:\n",
        "        for index, record in enumerate(sequence, 1):\n",
        "            if index == 1 or index % every == 0:\n",
        "                if is_iterator:\n",
        "                    label.value = '{name}: {index} / ?'.format(\n",
        "                        name=name,\n",
        "                        index=index\n",
        "                    )\n",
        "                else:\n",
        "                    progress.value = index\n",
        "                    label.value = u'{name}: {index} / {size}'.format(\n",
        "                        name=name,\n",
        "                        index=index,\n",
        "                        size=size\n",
        "                    )\n",
        "                    \n",
        "            yield record\n",
        "    except:\n",
        "        progress.bar_style = 'danger'\n",
        "        raise\n",
        "    else:\n",
        "        progress.bar_style = 'success'\n",
        "        progress.value = index\n",
        "        label.value = \"{name}: {index}\".format(\n",
        "            name=name,\n",
        "            index=str(index or '?')\n",
        "        )\n",
        "\n",
        "def try_makedirs(d):\n",
        "    import os\n",
        "    try:\n",
        "        os.makedirs(d)\n",
        "    except FileExistsError as e:\n",
        "        pass\n",
        "\n",
        "    \n",
        "def load_image(filename):\n",
        "    return \\\n",
        "        PIL.Image.open(filename)\\\n",
        "          .convert('RGB')\n",
        "\n",
        "    \n",
        "# def load_image(filename):\n",
        "#     return \\\n",
        "#         PIL.Image.open(filename)\\\n",
        "#           .resize((64,64), _interpolation_method)\\\n",
        "#           .convert('RGB')\n",
        "\n",
        "# def load_image(filename):\n",
        "#     return np.array(\n",
        "#         PIL.Image.open(filename)\\\n",
        "#           .resize((64,64), _interpolation_method)\\\n",
        "#           .convert('RGB'),\n",
        "#         dtype=np.float32\n",
        "#     )/255\n",
        "\n",
        "\n",
        "def plot_results(\n",
        "    results_1, model_1_name, model_1_color,\n",
        "    results_2, model_2_name, model_2_color\n",
        "):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    x = range(1, 1+results_1.shape[0])\n",
        "    one_plt = plt.plot(x, results_1[:,1], model_1_color + '-', x, results_1[:,1], model_1_color + 'o')\n",
        "    two_plt = plt.plot(x, results_2[:,1], model_2_color + '-', x, results_2[:,1], model_2_color + 'o')\n",
        "    \n",
        "    plt.legend((one_plt[0], two_plt[0]), (model_1_name, model_2_name))\n",
        "    plt.title('Model accuracy improvement over time')\n",
        "    plt.xlabel('# of epochs')\n",
        "    plt.xticks(np.linspace(1, results_1.shape[0], 11))\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.ylim(0, 100)\n",
        "    plt.yticks(np.linspace(0, 100, 11));\n",
        "    plt.draw()\n",
        "    \n",
        "    \n",
        "def plot_results_to_grid(\n",
        "    grid, where,\n",
        "    results_1, model_1_name, model_1_color,\n",
        "    results_2, model_2_name, model_2_color\n",
        "):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    with grid.output_to(where[0], where[1]):\n",
        "        grid.clear_cell()\n",
        "        plot_results(results_1, model_1_name, model_1_color, results_2, model_2_name, model_2_color)\n",
        "\n",
        "        \n",
        "def elapsed_time(model_name, i):\n",
        "    import time\n",
        "    \n",
        "    if 0 == i:\n",
        "        elapsed_time.start = time.time()\n",
        "    else:\n",
        "        print(\n",
        "            \"{{{}}} The last training epoch took {} seconds.\\n\\n\".format(\n",
        "                model_name, time.time() - elapsed_time.start\n",
        "            )\n",
        "        )\n",
        "        \n",
        "\n",
        "class CatchIO:\n",
        "    def __init__(self):\n",
        "        self._stdout = None\n",
        "        self.buffer = None\n",
        "    \n",
        "    def __enter__(self):\n",
        "        import sys\n",
        "        import io\n",
        "        \n",
        "        self._stdout = sys.stdout\n",
        "        sys.stdout = io.StringIO()\n",
        "    \n",
        "    def __exit__(self, type_, value, traceback):\n",
        "        import sys\n",
        "        \n",
        "        self.buffer = sys.stdout.getvalue()\n",
        "        sys.stdout = self._stdout\n",
        "        if value is not None:\n",
        "            raise value\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDVa_NYwJH_u"
      },
      "source": [
        "#Models and datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxuWtQ5tLCiy"
      },
      "source": [
        "#@title AlexNet{display-mode: \"form\"}\n",
        "from torchvision.models.alexnet import alexnet\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        " \n",
        "class AlexNet(nn.Module):\n",
        "  \n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.alex = alexnet(pretrained=_alex_pretrained, num_classes=1000);\n",
        "   \n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.alex.forward(x), dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sc2mKvqLE36"
      },
      "source": [
        "#@title SqueezeNet {display-mode: \"form\"}\n",
        "import torchvision.models.squeezenet\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SqueezeNet(nn.Module):\n",
        "  \n",
        "    def __init__(self):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        self.squeeze = torchvision.models.squeezenet.squeezenet1_0(pretrained=_squeeze_pretrained, num_classes=1000);\n",
        "   \n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.squeeze.forward(x), dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILsk-md9jUYc",
        "cellView": "form"
      },
      "source": [
        "#@title ImageNet-16 _(warning: very slow)_\n",
        "from torchvision.datasets import DatasetFolder\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "import pandas\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "\n",
        "path_to_ImageNet16 = \"COMP551_Assignment4/data/\" #@param {type:\"string\"}\n",
        "\n",
        "if \"ImageNet-16\" == _dataset:\n",
        "    IMGSZ = (16,16,3)\n",
        "    NUM_IMAGES = 1275273\n",
        "\n",
        "    train_pickle_folder = 'data/16/train/pickle'\n",
        "    train_image_folder = 'data/16/train/images'\n",
        "    valid_image_folder = 'data/16/validation/images'\n",
        "    test_pickle_folder = 'data/16/test/pickle'\n",
        "    test_image_folder = 'data/16/test/images'\n",
        "\n",
        "    force = False #@param {type:\"boolean\"}\n",
        "    train_valid_split = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "\n",
        "    ct = np.zeros(1000)\n",
        "\n",
        "    if not os.path.exists(train_image_folder) or force:\n",
        "        # Create folders\n",
        "        try_makedirs(train_pickle_folder)\n",
        "        try_makedirs(train_image_folder)\n",
        "        try_makedirs(valid_image_folder)\n",
        "        try_makedirs(test_pickle_folder)\n",
        "        try_makedirs(test_image_folder)\n",
        "        for ix in range(1000):\n",
        "            try_makedirs(os.path.join(train_image_folder, \"class_{}\".format(1+ix)))\n",
        "            try_makedirs(os.path.join(valid_image_folder, \"class_{}\".format(1+ix)))\n",
        "            try_makedirs(os.path.join(test_image_folder, \"class_{}\".format(1+ix)))\n",
        "        # Extract training data zipfile\n",
        "        z = ZipFile(\n",
        "            os.path.join(\n",
        "                '/gdrive/My Drive/', path_to_ImageNet16, 'Imagenet16_train.zip'\n",
        "            )\n",
        "        )\n",
        "        z.extractall(train_pickle_folder)\n",
        "        z.close()\n",
        "        # Extract training images to folders\n",
        "        for ix in log_progress(\n",
        "            range(1, 11), every=1, name=\"Converting pickle files to images\"\n",
        "        ):\n",
        "            # Read pickle\n",
        "            tmp = pandas.read_pickle(\n",
        "                os.path.join(train_pickle_folder, 'train_data_batch_{}'.format(ix))\n",
        "            )\n",
        "            # CIFAR format to array of images\n",
        "            train_images = tmp['data'] \\\n",
        "              .reshape(-1, IMGSZ[2], IMGSZ[0], IMGSZ[1]) \\\n",
        "              .transpose([0, 2, 3, 1])\n",
        "            # Save images to png (lossless format)\n",
        "            for jx in range(len(train_images)):\n",
        "                label = tmp['labels'][jx]\n",
        "                # Split training set into training and validation sets\n",
        "                if ct[label-1] > np.floor(train_valid_split * NUM_IMAGES / 1000):\n",
        "                    # validation\n",
        "                    out_folder = valid_image_folder\n",
        "                else:\n",
        "                    # training\n",
        "                    out_folder = train_image_folder\n",
        "                    ct[label-1] = 1 + ct[label-1]\n",
        "                # Save\n",
        "                PIL.Image.fromarray(train_images[jx]).save(\n",
        "                    os.path.join(\n",
        "                        out_folder,\n",
        "                        'class_{}'.format(label),\n",
        "                        '{}.png'.format(jx)\n",
        "                    )\n",
        "                )\n",
        "            # Remove pickle file since we're done with it\n",
        "            os.remove(\n",
        "                os.path.join(train_pickle_folder, 'train_data_batch_{}'.format(ix))\n",
        "            )\n",
        "\n",
        "        # Extract test data zipfile\n",
        "        z = ZipFile(\n",
        "            os.path.join(\n",
        "                '/gdrive/My Drive/', path_to_ImageNet16, 'Imagenet16_val.zip'\n",
        "            )\n",
        "        )\n",
        "        z.extractall(test_pickle_folder)\n",
        "        z.close()\n",
        "        # Extract test images to folders\n",
        "        #   Read pickle\n",
        "        tmp = pandas.read_pickle(os.path.join(test_pickle_folder, 'val_data'))\n",
        "        #   CIFAR format to array of images\n",
        "        test_images = tmp['data'] \\\n",
        "          .reshape(-1, IMGSZ[2], IMGSZ[0], IMGSZ[1]) \\\n",
        "          .transpose([0, 2, 3, 1])\n",
        "        #   Save images to png (lossless format)\n",
        "        for jx in range(len(test_images)):\n",
        "            # Save\n",
        "            PIL.Image.fromarray(test_images[jx]).save(\n",
        "                os.path.join(\n",
        "                    test_image_folder,\n",
        "                    'class_{}'.format(tmp['labels'][jx]),\n",
        "                    '{}.png'.format(jx)\n",
        "                )\n",
        "            )\n",
        "        #   Remove pickle file since we're done with it\n",
        "        os.remove(\n",
        "            os.path.join(test_pickle_folder, 'val_data')\n",
        "        )\n",
        "\n",
        "    trainset = DatasetFolder(\n",
        "        train_image_folder, load_image, ['png'],\n",
        "        transform=_transformations\n",
        "    )\n",
        "    validset = DatasetFolder(\n",
        "        valid_image_folder, load_image, ['png'],\n",
        "        transform=_transformations\n",
        "    )\n",
        "    testset = DatasetFolder(\n",
        "        test_image_folder, load_image, ['png'],\n",
        "        transform=_transformations\n",
        "    )\n",
        "\n",
        "else:\n",
        "    print('Disabled')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yukY8MyoV82C",
        "cellView": "form"
      },
      "source": [
        "#@title CIFAR-10\n",
        "from torchvision.datasets import DatasetFolder\n",
        "import tarfile\n",
        "import os\n",
        "import pandas\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "\n",
        "path_to_CIFAR10 = \"COMP551_Assignment4/data/\" #@param {type:\"string\"}\n",
        "\n",
        "if \"CIFAR-10\" == _dataset:\n",
        "    IMGSZ = (32, 32, 3)\n",
        "    NUM_IMAGES = 50000\n",
        "    NUM_CLASSES = 10\n",
        "\n",
        "    pickle_folder = 'data/CIFAR10/pickle'\n",
        "    train_image_folder = 'data/CIFAR10/train/images'\n",
        "    valid_image_folder = 'data/CIFAR10/validation/images'\n",
        "    test_image_folder = 'data/CIFAR10/test/images'\n",
        "\n",
        "    force = False #@param {type:\"boolean\"}\n",
        "    train_valid_split = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "\n",
        "    ct = np.zeros(NUM_CLASSES)\n",
        "\n",
        "    if not os.path.exists(train_image_folder) or force:\n",
        "        # Create folders\n",
        "        try_makedirs(pickle_folder)\n",
        "        try_makedirs(train_image_folder)\n",
        "        try_makedirs(valid_image_folder)\n",
        "        try_makedirs(test_image_folder)\n",
        "        for ix in range(NUM_CLASSES):\n",
        "            try_makedirs(os.path.join(train_image_folder, \"class_{}\".format(ix)))\n",
        "            try_makedirs(os.path.join(valid_image_folder, \"class_{}\".format(ix)))\n",
        "            try_makedirs(os.path.join(test_image_folder, \"class_{}\".format(ix)))\n",
        "        # Extract training data zipfile\n",
        "        tar = tarfile.open(\n",
        "            os.path.join(\n",
        "                '/gdrive/My Drive/', path_to_CIFAR10, 'cifar-10-python.tar.gz'\n",
        "            )\n",
        "        )\n",
        "        tar.extractall(pickle_folder)\n",
        "        tar.close()\n",
        "        # Extract training images to folders\n",
        "        for ix in log_progress(\n",
        "            range(1, 6), every=1, name=\"Converting pickle files to images\"\n",
        "        ):\n",
        "            # Read pickle\n",
        "            tmp = pandas.read_pickle(\n",
        "                os.path.join(\n",
        "                    pickle_folder, 'cifar-10-batches-py', 'data_batch_{}'.format(ix)\n",
        "                )\n",
        "            )\n",
        "            # CIFAR format to array of images\n",
        "            train_images = tmp['data'] \\\n",
        "              .reshape(-1, IMGSZ[2], IMGSZ[0], IMGSZ[1]) \\\n",
        "              .transpose([0, 2, 3, 1])\n",
        "            # Save images to png (lossless format)\n",
        "            for jx in range(len(train_images)):\n",
        "                label = tmp['labels'][jx]\n",
        "                # Split training set into training and validation sets\n",
        "                if ct[label-1] >= np.floor(train_valid_split * NUM_IMAGES / NUM_CLASSES):\n",
        "                    # validation\n",
        "                    out_folder = valid_image_folder\n",
        "                else:\n",
        "                    # training\n",
        "                    out_folder = train_image_folder\n",
        "                    ct[label-1] = 1 + ct[label-1]\n",
        "                # Save\n",
        "                PIL.Image.fromarray(train_images[jx]).save(\n",
        "                    os.path.join(\n",
        "                        out_folder,\n",
        "                        'class_{}'.format(label),\n",
        "                        '{}.png'.format(jx)\n",
        "                    )\n",
        "                )\n",
        "            # Remove pickle file since we're done with it\n",
        "            os.remove(\n",
        "                os.path.join(\n",
        "                    pickle_folder,\n",
        "                    'cifar-10-batches-py', \n",
        "                    'data_batch_{}'.format(ix)\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Extract test images to folders\n",
        "        #   Read pickle\n",
        "        tmp = pandas.read_pickle(\n",
        "            os.path.join(pickle_folder, 'cifar-10-batches-py', 'test_batch')\n",
        "        )\n",
        "        #   CIFAR format to array of images\n",
        "        test_images = tmp['data']\\\n",
        "          .reshape(-1, IMGSZ[2], IMGSZ[0], IMGSZ[1]) \\\n",
        "          .transpose([0, 2, 3, 1])\n",
        "        #   Save images to png (lossless format)\n",
        "        for jx in range(len(test_images)):\n",
        "            # Save\n",
        "            PIL.Image.fromarray(test_images[jx]).save(\n",
        "                os.path.join(\n",
        "                    test_image_folder,\n",
        "                    'class_{}'.format(tmp['labels'][jx]),\n",
        "                    '{}.png'.format(jx)\n",
        "                )\n",
        "            )\n",
        "        #   Remove pickle file since we're done with it\n",
        "        os.remove(\n",
        "            os.path.join(pickle_folder, 'cifar-10-batches-py', 'test_batch')\n",
        "        )\n",
        "    trainset = DatasetFolder(\n",
        "        train_image_folder, load_image, ['png'],\n",
        "        transform=_transformations\n",
        "    )\n",
        "    validset = DatasetFolder(\n",
        "        valid_image_folder, load_image, ['png'],\n",
        "        transform=_transformations\n",
        "    )\n",
        "    testset = DatasetFolder(\n",
        "        test_image_folder, load_image, ['png'],\n",
        "        transform=_transformations\n",
        "    )\n",
        "\n",
        "else:\n",
        "    print('Disabled')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFa3BL1PjSqH",
        "cellView": "form"
      },
      "source": [
        "#@title CIFAR-100\n",
        "from torchvision.datasets import DatasetFolder\n",
        "import tarfile\n",
        "import os\n",
        "import pandas\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "\n",
        "path_to_CIFAR100 = \"COMP551_Assignment4/data/\" #@param {type:\"string\"}\n",
        "\n",
        "if \"CIFAR-100\" == _dataset:\n",
        "    print('Loading CIFAR-100... ', end='')\n",
        "    \n",
        "    IMGSZ = (32, 32, 3)\n",
        "    NUM_IMAGES = 50000\n",
        "    NUM_CLASSES = 100\n",
        "\n",
        "    pickle_folder = 'data/CIFAR100/pickle'\n",
        "    train_image_folder = 'data/CIFAR100/train/images'\n",
        "    valid_image_folder = 'data/CIFAR100/validation/images'\n",
        "    test_image_folder = 'data/CIFAR100/test/images'\n",
        "\n",
        "    label_type = \"fine (100)\" #@param [\"fine (100)\", \"coarse (20)\"]\n",
        "    if label_type == \"fine (100)\":\n",
        "        label_type = \"fine_labels\"\n",
        "    elif label_type == \"coarse (20)\":\n",
        "        label_type = \"coarse_labels\"\n",
        "    \n",
        "    force = False #@param {type:\"boolean\"}\n",
        "    train_valid_split = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "\n",
        "    ct = np.zeros(NUM_CLASSES)\n",
        "\n",
        "    if not os.path.exists(train_image_folder) or force:\n",
        "        # Create folders\n",
        "        try_makedirs(pickle_folder)\n",
        "        try_makedirs(train_image_folder)\n",
        "        try_makedirs(valid_image_folder)\n",
        "        try_makedirs(test_image_folder)\n",
        "        for ix in range(NUM_CLASSES):\n",
        "            try_makedirs(os.path.join(train_image_folder, \"class_{}\".format(ix)))\n",
        "            try_makedirs(os.path.join(valid_image_folder, \"class_{}\".format(ix)))\n",
        "            try_makedirs(os.path.join(test_image_folder, \"class_{}\".format(ix)))\n",
        "        # Extract training data zipfile\n",
        "        tar = tarfile.open(\n",
        "            os.path.join(\n",
        "                '/gdrive/My Drive/', path_to_CIFAR100, 'cifar-100-python.tar.gz'\n",
        "            )\n",
        "        )\n",
        "        tar.extractall(pickle_folder)\n",
        "        tar.close()\n",
        "        # Extract training images to folders\n",
        "        # Read pickle\n",
        "        tmp = pandas.read_pickle(\n",
        "            os.path.join(pickle_folder, 'cifar-100-python', 'train')\n",
        "        )\n",
        "        tmp.keys()\n",
        "        # CIFAR format to array of images\n",
        "        train_images = tmp['data'] \\\n",
        "          .reshape(-1, IMGSZ[2], IMGSZ[0], IMGSZ[1]) \\\n",
        "          .transpose([0, 2, 3, 1])\n",
        "        # Save images to png (lossless format)\n",
        "        for jx in range(len(train_images)):\n",
        "            label = tmp[label_type][jx]\n",
        "            # Split training set into training and validation sets\n",
        "            if ct[label-1] > np.floor(train_valid_split * NUM_IMAGES / NUM_CLASSES):\n",
        "                # validation\n",
        "                out_folder = valid_image_folder\n",
        "            else:\n",
        "                # training\n",
        "                out_folder = train_image_folder\n",
        "                ct[label-1] = 1 + ct[label-1]\n",
        "            # Save\n",
        "            PIL.Image.fromarray(train_images[jx]).save(\n",
        "                os.path.join(\n",
        "                    out_folder,\n",
        "                    'class_{}'.format(label),\n",
        "                    '{}.png'.format(jx)\n",
        "                )\n",
        "            )\n",
        "        # Remove pickle file since we're done with it\n",
        "        os.remove(os.path.join(pickle_folder, 'cifar-100-python', 'train'))\n",
        "\n",
        "        # Extract test images to folders\n",
        "        #   Read pickle\n",
        "        tmp = pandas.read_pickle(\n",
        "            os.path.join(pickle_folder, 'cifar-100-python', 'test')\n",
        "        )\n",
        "        #   CIFAR format to array of images\n",
        "        test_images = tmp['data']\\\n",
        "          .reshape(-1, IMGSZ[2], IMGSZ[0], IMGSZ[1]) \\\n",
        "          .transpose([0, 2, 3, 1])\n",
        "        #   Save images to png (lossless format)\n",
        "        for jx in range(len(test_images)):\n",
        "            # Save\n",
        "            PIL.Image.fromarray(test_images[jx]).save(\n",
        "                os.path.join(\n",
        "                    test_image_folder,\n",
        "                    'class_{}'.format(tmp[label_type][jx]),\n",
        "                    '{}.png'.format(jx)\n",
        "                )\n",
        "            )\n",
        "        #   Remove pickle file since we're done with it\n",
        "        os.remove(\n",
        "            os.path.join(pickle_folder, 'cifar-100-python', 'test')\n",
        "        )\n",
        "    \n",
        "    trainset = DatasetFolder(\n",
        "        train_image_folder, load_image, ['png'],\n",
        "        transform=_transformations\n",
        "    )\n",
        "    validset = DatasetFolder(\n",
        "        valid_image_folder, load_image, ['png'],\n",
        "        transform=_transformations\n",
        "    )\n",
        "    testset = DatasetFolder(\n",
        "        test_image_folder, load_image, ['png'],\n",
        "        transform=_transformations\n",
        "    )\n",
        "    \n",
        "    print('Done.')\n",
        "    \n",
        "else:\n",
        "    print('Disabled')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrjWvxexUwdW",
        "cellView": "form"
      },
      "source": [
        "#@title CINIC-10\n",
        "from torchvision.datasets import ImageFolder\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "path_to_CINIC = \"NordVPN216856 \" #@param {type:\"string\"}\n",
        "force = False #@param {type:\"boolean\"}\n",
        "image_folder = 'data/CINIC-10'\n",
        "\n",
        "if \"CINIC-10\" == _dataset:\n",
        "    print('Loading CIFAR-100... ', end='')\n",
        "\n",
        "    if not os.path.exists(image_folder) or force:\n",
        "        tar = tarfile.open(os.path.join('/gdrive/My Drive/', path_to_CINIC))\n",
        "        try_makedirs(image_folder)\n",
        "        tar.extractall(image_folder)\n",
        "        tar.close()\n",
        "\n",
        "    trainset = ImageFolder(\n",
        "        os.path.join(image_folder, 'train'),\n",
        "        loader=load_image,\n",
        "        transform=_transformations\n",
        "    )\n",
        "    validset = ImageFolder(\n",
        "        os.path.join(image_folder, 'valid'),\n",
        "        loader=load_image,\n",
        "        transform=_transformations\n",
        "    )\n",
        "    testset = ImageFolder(\n",
        "        os.path.join(image_folder, 'test'),\n",
        "        loader=load_image,\n",
        "        transform=_transformations\n",
        "    )\n",
        "    \n",
        "    print('done')\n",
        "\n",
        "else:\n",
        "    print('Disabled')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g54Ru642KcgQ",
        "cellView": "form"
      },
      "source": [
        "#@title Dataloader and model initialization\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "def train(model, model_name, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % _log_interval == 0:\n",
        "            print('{{{}}} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    model_name, epoch, batch_idx * len(data),\n",
        "                    len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "def validate(model, model_name, device, validation_loader):\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in validation_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            # sum up batch loss\n",
        "            validation_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            # get the index of the max log-probability\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    validation_loss /= len(validation_loader.dataset)\n",
        "\n",
        "    print(\n",
        "        '\\n{{{}}} Validation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
        "        .format(\n",
        "            model_name, validation_loss, correct,\n",
        "            len(validation_loader.dataset),\n",
        "            100. * correct / len(validation_loader.dataset)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return validation_loss, 100. * correct / len(validation_loader.dataset)\n",
        "\n",
        "\n",
        "def test(model, model_name, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            # sum up batch loss\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            # get the index of the max log-probability\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print(\n",
        "        '\\n{{{}}} Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
        "        .format(\n",
        "            model_name, test_loss, correct, len(test_loader.dataset),\n",
        "            100. * correct / len(test_loader.dataset)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return test_loss, 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "\n",
        "def train_nonan(model, model_name, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % _log_interval == 0:\n",
        "            print('{{{}}} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    model_name, epoch, batch_idx * len(data),\n",
        "                    len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()\n",
        "                )\n",
        "            )\n",
        "    \n",
        "    # Need to finish batch so that loader will reset for next model/batch\n",
        "    return not np.isnan(loss.cpu().detach().numpy())\n",
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNn2IFHic0Iy"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\n",
        "    len(trainset),\n",
        "    len(validset),\n",
        "    len(trainset) / (len(trainset) + len(validset)),\n",
        "    len(testset)\n",
        ")\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(trainset[0][0].numpy().transpose([1, 2, 0]))\n",
        "plt.title('training set')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(validset[0][0].numpy().transpose([1, 2, 0]))\n",
        "plt.title('validation set')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(testset[0][0].numpy().transpose([1, 2, 0]));\n",
        "plt.title('test set')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHt5Q3qKKV7_"
      },
      "source": [
        "#Training and results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E60iTJakwcyS"
      },
      "source": [
        "#@title Learning parameter grid search\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab import widgets\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "import datetime\n",
        "\n",
        "drive_savefolder = \"COMP551_Assignment4/\" #@param {type:\"string\"}\n",
        "\n",
        "grid = widgets.Grid(2, 1)\n",
        "\n",
        "# BatchSize = [64, 512, 1024]\n",
        "# LearningRate = [0.05, 0.01, 0.001]\n",
        "# Momentum = [0.9, 0.5, 0.1]\n",
        "# WeightDecay = [0, 0.0002]\n",
        "\n",
        "BatchSize = [64]\n",
        "LearningRate = [0.05, 0.01, 0.001]\n",
        "Momentum = [0.9, 0.5, 0.1]\n",
        "WeightDecay = [0]\n",
        "\n",
        "# BatchSize = [1024]\n",
        "# LearningRate = [0.01, 0.001]\n",
        "# Momentum = [0.9, 0.5, 0.1]\n",
        "# WeightDecay = [0, 0.0002]\n",
        "\n",
        "# BatchSize = [512]\n",
        "# LearningRate = [0.001]\n",
        "# Momentum = [0.9, 0.1]\n",
        "# WeightDecay = [0.0002]\n",
        "\n",
        "\n",
        "space = [BatchSize, LearningRate, Momentum, WeightDecay]\n",
        "search = {}\n",
        "num = np.ones(len(space), dtype=int)\n",
        "for ix, ll in enumerate(space[1:]):\n",
        "    num[:1+ix] *= len(ll)\n",
        "    \n",
        "for ix in range(np.prod([len(ll) for ll in space])):\n",
        "    key = [[]]*len(space)\n",
        "    for jx, ll in enumerate(space):\n",
        "        key[jx] = ll[int(ix / num[jx]) % len(ll)]\n",
        "    search[tuple(key)] = 0\n",
        "\n",
        "for params in search.keys():\n",
        "    alex_good = True\n",
        "    squeeze_good = True\n",
        "    \n",
        "    # Parameters\n",
        "    _batch_size = params[0]\n",
        "    _learning_rate = params[1]\n",
        "    _momentum = params[2]\n",
        "    _weight_decay = params[3]\n",
        "    \n",
        "    # Initialize training, validation, and test loaders\n",
        "    train_loader = DataLoader(trainset, batch_size=_batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(validset, batch_size=_batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(testset, batch_size=_batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize AlexNet\n",
        "    if _alex_enabled:\n",
        "        alex = AlexNet().to(\"cuda\")\n",
        "        alex_opt = optim.SGD(\n",
        "            alex.parameters(), lr=_learning_rate, momentum=_momentum,\n",
        "            weight_decay=_weight_decay\n",
        "        )\n",
        "    # Initialize SqueezeNet\n",
        "    squeeze = SqueezeNet().to(\"cuda\")\n",
        "    squeeze_opt = optim.SGD(\n",
        "        squeeze.parameters(), lr=_learning_rate, momentum=_momentum,\n",
        "        weight_decay=_weight_decay\n",
        "    )\n",
        "    \n",
        "    # Initialize result arrays\n",
        "    if _alex_enabled or 'alex_results' not in locals():\n",
        "        alex_results = np.full((1+_nb_epochs, 2), np.nan)\n",
        "    squeeze_results = np.full((1+_nb_epochs, 2), np.nan)\n",
        "    \n",
        "    # Train\n",
        "    for epoch in range(1, _nb_epochs + 1):\n",
        "        # Display training output\n",
        "        with grid.output_to(1, 0):\n",
        "            if _alex_enabled:\n",
        "                # No point in training AlexNet if the weights have exploded to NaN values\n",
        "                if alex_good:\n",
        "                    alex_good = train_nonan(alex, \"AlexNet\", \"cuda\", train_loader, alex_opt, epoch)\n",
        "                # No point in validating AlexNet either (will inevitably give ~1/num_classes accuracy)\n",
        "                if alex_good:\n",
        "                    alex_results[epoch-1, :] = validate(alex, \"AlexNet\", \"cuda\", valid_loader)\n",
        "\n",
        "            if squeeze_good:\n",
        "                squeeze_good = train_nonan(squeeze, \"SqueezeNet\", \"cuda\", train_loader, squeeze_opt, epoch)\n",
        "            if squeeze_good:\n",
        "                squeeze_results[epoch-1, :2] = validate(squeeze, \"SqueezeNet\", \"cuda\", valid_loader)\n",
        "\n",
        "        plot_results_to_grid(grid, (0, 0), alex_results, \"AlexNet\", \"r\", squeeze_results, \"SqueezeNet\", \"b\")\n",
        "        \n",
        "        if not (_alex_enabled and alex_good) and not squeeze_good:\n",
        "            print('\\n=================\\nInterrupting training for set of parameters (NaN)\\n=================\\n\\n')\n",
        "            break\n",
        "\n",
        "\n",
        "    if _alex_enabled and alex_good:\n",
        "        alex_results[-1, :2] = test(alex, \"AlexNet\", \"cuda\", test_loader)\n",
        "    if squeeze_good:\n",
        "        squeeze_results[-1, :2] = test(squeeze, \"SqueezeNet\", \"cuda\", test_loader)\n",
        "    \n",
        "    params_to_save = \\\n",
        "    {\n",
        "        'squeeze_pretrained': _squeeze_pretrained,\n",
        "        'nb_epochs': _nb_epochs,\n",
        "        'dataset': _dataset,\n",
        "        'batch_size': params[0],\n",
        "        'learning_rate': params[1],\n",
        "        'momentum': params[2],\n",
        "        'weight_decay': params[3]\n",
        "    }\n",
        "    \n",
        "    joblib.dump(\n",
        "        [params_to_save, alex_results, squeeze_results],\n",
        "        os.path.join(\n",
        "            '/gdrive/My Drive/', drive_savefolder, 'alex_squeeze_grid_{}.joblib'.format(\n",
        "                datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    search[params] = [alex_results[-1,1], squeeze_results[-1,1]]\n",
        "    \n",
        "joblib.dump(search, os.path.join('/gdrive/My Drive/', drive_savefolder, 'search_{}.joblib'.format(\n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
        ")))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}